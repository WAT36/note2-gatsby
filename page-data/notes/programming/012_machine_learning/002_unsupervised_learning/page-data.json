{"componentChunkName":"component---src-templates-note-dir-js","path":"/notes/programming/012_machine_learning/002_unsupervised_learning","result":{"data":{"site":{"siteMetadata":{"title":"WAT Note(II)"}},"allDirectory":{"nodes":[]},"allMarkdownRemark":{"nodes":[{"excerpt":"教師なし学習について。 教師なし学習は教師あり学習とは違い、入力データに対する答え(目標データ)が与えられず、入力データからデータの特徴などを出力する手法である。 具体的な例としては、クラスタリング、異常検知、主成分分析などがある。","fields":{"slug":"/programming/012_machine_learning/002_unsupervised_learning/unsupervised_learning/"},"frontmatter":{"date":"October 26, 2019","title":"教師なし学習","description":""}},{"excerpt":"…","fields":{"slug":"/programming/012_machine_learning/002_unsupervised_learning/clustering/"},"frontmatter":{"date":"October 28, 2019","title":"クラスタリング","description":""}},{"excerpt":"クラスタリングの手法の一つ、K-means法についてを述べる。 先ほども示した以下のデータを例にとって、大まかな手順を、以下に記載しながら進める。  1. クラスタの数を定める K-means…","fields":{"slug":"/programming/012_machine_learning/002_unsupervised_learning/k-means/"},"frontmatter":{"date":"October 28, 2019","title":"K-Means法","description":""}},{"excerpt":"…","fields":{"slug":"/programming/012_machine_learning/002_unsupervised_learning/distortion_measure/"},"frontmatter":{"date":"October 28, 2019","title":"歪み尺度","description":""}},{"excerpt":"先程のk-means法では、データを必ずどれか一つのクラスターに割り当てていたが、複数のクラスターに割り当てると言うことはできないだろうか？ ここで、教師あり学習でも利用した、確率を使った表現を利用することを考えてみる。 k-means…","fields":{"slug":"/programming/012_machine_learning/002_unsupervised_learning/gaussian_mixture_model/"},"frontmatter":{"date":"October 28, 2019","title":"混合ガウスモデル","description":""}}]}},"pageContext":{"absolutePath":"/Users/watarutsukagoshi/Desktop/WTFiles/gatsby-blog/wat-note2/content/notes/programming/012_machine_learning/002_unsupervised_learning","markdownRegexPath":"//Users/watarutsukagoshi/Desktop/WTFiles/gatsby-blog/wat-note2/content/notes/programming/012_machine_learning/002_unsupervised_learning/[^/]*.md/"}},"staticQueryHashes":["2841359383","3257411868"]}